# -*- coding: utf-8 -*-
"""task_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FkS2BsZmvXbldTeq8PS-6oWWPnFRsbYh
"""

import pandas as pd

import pandas as pd

def generate_car_matrix(df: pd.DataFrame) -> pd.DataFrame:

    car_matrix = df.pivot_table(index='id_1', columns='id_2', values='car', aggfunc='sum', fill_value=0)
    return car_matrix

# Read the CSV file into a DataFrame
df = pd.read_csv("/content/dataset-1.csv")

# Call the function with the DataFrame
result_matrix = generate_car_matrix(df)
print(result_matrix)

import pandas as pd

def get_type_count(dataframe):
    # Add a new categorical column 'car_type' based on the 'car' column
    dataframe['car_type'] = pd.cut(dataframe['car'],
                                   bins=[float('-inf'), 15, 25, float('inf')],
                                   labels=['low', 'medium', 'high'],
                                   right=False)

    # Calculate the count of occurrences for each 'car_type'
    type_counts = dataframe['car_type'].value_counts().to_dict()

    # Sort the dictionary alphabetically based on keys
    sorted_type_counts = dict(sorted(type_counts.items()))

    return sorted_type_counts
# You can read the CSV file into a DataFrame using pd.read_csv
file_path = '/content/dataset-1.csv'
df = pd.read_csv(file_path)

# Call the function with the DataFrame
result = get_type_count(df)

# Print the result
print(result)

import pandas as pd

def get_bus_indexes(dataframe):
    # Calculate the mean value of the 'bus' column
    mean_bus_value = dataframe['bus'].mean()

    # Identify indices where 'bus' values are greater than twice the mean
    bus_indexes = dataframe[dataframe['bus'] > 2 * mean_bus_value].index.tolist()

    # Sort the indices in ascending order
    bus_indexes.sort()

    return bus_indexes

# You can read the CSV file into a DataFrame using pd.read_csv
file_path = '/content/dataset-1.csv'
df = pd.read_csv(file_path)

# Call the function with the DataFrame
result = get_bus_indexes(df)

# Print the result
print(result)

import pandas as pd

def filter_routes(dataframe):
    # Calculate the average values of the 'truck' column for each 'route'
    avg_truck_values = dataframe.groupby('route')['truck'].mean()

    # Filter routes where the average 'truck' value is greater than 7
    filtered_routes = avg_truck_values[avg_truck_values > 7].index.tolist()

    # Sort the list of routes in ascending order
    filtered_routes.sort()

    return filtered_routes


file_path = '/content/dataset-1.csv'
df = pd.read_csv(file_path)

# Call the function with the DataFrame
result = filter_routes(df)

# Print the result
print(result)

import pandas as pd

def multiply_matrix(input_dataframe):
    # Create a copy of the input DataFrame to avoid modifying the original
    result_dataframe = input_dataframe.copy()

    # Apply the multiplication logic based on the given conditions
    result_dataframe = result_dataframe.applymap(lambda x: x * 0.75 if x > 20 else x * 1.25)

    # Round the values to 1 decimal place
    result_dataframe = result_dataframe.round(1)

    return result_dataframe

# Assuming 'dataset-1.csv' is the file containing your dataset
# You can read the CSV file into a DataFrame using pd.read_csv
file_path = '/content/dataset-1.csv'
df = pd.read_csv(file_path)

# Assuming 'get_type_count' function from Question 1 returns the resulting DataFrame
resulting_dataframe = get_type_count(df)

# Call the function with the resulting DataFrame
modified_dataframe = multiply_matrix(resulting_dataframe)

# Print the modified DataFrame
print(modified_dataframe)

import pandas as pd

def verify_timestamps(dataframe):
    try:
        # Combine date and time columns to create datetime objects
        dataframe['start_datetime'] = pd.to_datetime(dataframe['startDay'] + ' ' + dataframe['startTime'])
        dataframe['end_datetime'] = pd.to_datetime(dataframe['endDay'] + ' ' + dataframe['endTime'])
    except pd.errors.OutOfBoundsDatetime as e:
        print(f"Error: {e}")
        return pd.Series(False, index=dataframe.index)  # Return False for all rows if there's an error

    # Check for missing or null datetime values
    if dataframe['start_datetime'].isnull().any() or dataframe['end_datetime'].isnull().any():
        return pd.Series(False, index=dataframe.index)  # Return False for all rows if there are missing or null values

    # Calculate the time difference for each record
    time_diff = dataframe['end_datetime'] - dataframe['start_datetime']

    # Check if time difference is equal to 24 hours and spans all 7 days
    correct_timestamps = (time_diff == pd.Timedelta(days=1)) & (dataframe['start_datetime'].dt.day_name() == dataframe['end_datetime'].dt.day_name())

    # Group by ('id', 'id_2') and check if all records for each group have correct timestamps
    result_series = correct_timestamps.groupby(['id', 'id_2']).all()

    return result_series


file_path = '/content/dataset-2.csv'
df = pd.read_csv(file_path)

# Call the function with the DataFrame
result_series = verify_timestamps(df)

# Print the result
print(result_series)