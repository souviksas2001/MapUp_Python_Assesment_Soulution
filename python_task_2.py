# -*- coding: utf-8 -*-
"""python_task_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/167Xc8_JTZoHVXzptNRNM3G8r5Lqr86M8
"""

import pandas as pd

pip install pandas networkx

df = pd.read_csv("/content/dataset-3.csv")

"""Question 1

"""

import pandas as pd
import networkx as nx

def calculate_distance_matrix(csv_file):
    # Read the CSV file into a DataFrame
    df = pd.read_csv(csv_file)

    # Create a directed graph using networkx
    G = nx.Graph()

    # Add edges and their distances to the graph
    for index, row in df.iterrows():
        G.add_edge(row['id_start'], row['id_end'], distance=row['distance'])
        G.add_edge(row['id_end'], row['id_start'], distance=row['distance'])  # Bidirectional edge

    # Initialize a matrix to store the cumulative distances
    num_nodes = len(G.nodes)
    distance_matrix = pd.DataFrame(index=G.nodes, columns=G.nodes, dtype=float)

    # Calculate cumulative distances between nodes
    for node1 in G.nodes:
        for node2 in G.nodes:
            if node1 == node2:
                distance_matrix.at[node1, node2] = 0  # Diagonal values set to 0
            else:
                # Use networkx to find the shortest path distance
                try:
                    distance_matrix.at[node1, node2] = nx.shortest_path_length(G, node1, node2, weight='distance')
                except nx.NetworkXNoPath:
                    # If no path exists, set the distance to infinity
                    distance_matrix.at[node1, node2] = float('inf')

    # Ensure the matrix is symmetric
    distance_matrix = distance_matrix.add(distance_matrix.T) / 2

    return distance_matrix

# Example usage
csv_file_path = 'dataset-3.csv'
result_matrix = calculate_distance_matrix(csv_file_path)
print(result_matrix)

"""Question 2"""

import pandas as pd

def unroll_distance_matrix(distance_matrix):
    # Create an empty list to store unrolled data
    unrolled_data = []

    # Iterate over the rows and columns of the distance matrix
    for id_start in distance_matrix.index:
        for id_end in distance_matrix.columns:
            # Skip rows where id_start is equal to id_end
            if id_start != id_end:
                # Extract the distance from the matrix
                distance = distance_matrix.at[id_start, id_end]

                # Append the data to the list
                unrolled_data.append({'id_start': id_start, 'id_end': id_end, 'distance': distance})

    # Create a DataFrame from the list of dictionaries
    unrolled_df = pd.DataFrame(unrolled_data)

    return unrolled_df

# Example usage
csv_file_path = 'dataset-3.csv'
result_matrix = calculate_distance_matrix(csv_file_path)
unrolled_df = unroll_distance_matrix(result_matrix)
print(unrolled_df)

"""Question 3"""

import pandas as pd

def find_ids_within_ten_percentage_threshold(data_frame, reference_value):
    # Filter rows where id_start is equal to the reference value
    reference_rows = data_frame[data_frame['id_start'] == reference_value]

    # Calculate the average distance for the reference value
    average_distance = reference_rows['distance'].mean()

    # Calculate the lower and upper bounds for the 10% threshold
    lower_bound = 0.9 * average_distance
    upper_bound = 1.1 * average_distance

    # Filter rows where distances are within the 10% threshold
    within_threshold = data_frame[(data_frame['distance'] >= lower_bound) & (data_frame['distance'] <= upper_bound)]

    # Get unique values from id_start column and sort them
    result_ids = within_threshold['id_start'].unique()
    result_ids.sort()

    return result_ids.tolist()

# Example usage
csv_file_path = 'dataset-3.csv'  # Replace with the actual file path
result_matrix = calculate_distance_matrix(csv_file_path)
unrolled_df = unroll_distance_matrix(result_matrix)

# Assuming 'id_start' is the correct column name, replace it if needed
reference_value = 1001400  # Replace with your desired reference value
result_ids = find_ids_within_ten_percentage_threshold(unrolled_df, reference_value)

print(result_ids)

"""Question 4"""

import pandas as pd

def calculate_toll_rate(data_frame):
    # Define rate coefficients for each vehicle type
    rate_coefficients = {
        'moto': 0.8,
        'car': 1.2,
        'rv': 1.5,
        'bus': 2.2,
        'truck': 3.6
    }

    # Calculate toll rates for each vehicle type
    for vehicle_type, rate_coefficient in rate_coefficients.items():
        column_name = vehicle_type  # Column name for the new column
        data_frame[column_name] = data_frame['distance'] * rate_coefficient

    return data_frame

# Example usage
csv_file_path = 'dataset-3.csv'  # Replace with the actual file path
result_matrix = calculate_distance_matrix(csv_file_path)
unrolled_df = unroll_distance_matrix(result_matrix)

# Assuming 'distance' is the correct column name, replace it if needed
result_df = calculate_toll_rate(unrolled_df)

print(result_df)

"""Question 5"""

import pandas as pd
from datetime import time, timedelta

def calculate_time_based_toll_rates(data_frame):
    # Define time ranges
    weekday_ranges = [
        (time(0, 0, 0), time(10, 0, 0), 0.8),
        (time(10, 0, 0), time(18, 0, 0), 1.2),
        (time(18, 0, 0), time(23, 59, 59), 0.8)
    ]
    weekend_ranges = [(time(0, 0, 0), time(23, 59, 59), 0.7)]

    # Initialize an empty list to store time-based toll rates
    time_based_rates = []

    # Iterate over unique ('id_start', 'id_end') pairs
    for _, group in data_frame.groupby(['id_start', 'id_end']):
        for day in range(7):  # Cover all 7 days of the week
            for start_time, end_time, discount_factor in weekday_ranges if day < 5 else weekend_ranges:
                start_datetime = pd.Timestamp.now().replace(hour=start_time.hour, minute=start_time.minute, second=start_time.second, microsecond=0)
                start_datetime += timedelta(days=day)

                end_datetime = pd.Timestamp.now().replace(hour=end_time.hour, minute=end_time.minute, second=end_time.second, microsecond=0)
                end_datetime += timedelta(days=day)

                time_based_rates.append({
                    'id_start': group['id_start'].iloc[0],
                    'id_end': group['id_end'].iloc[0],
                    'start_day': start_datetime.strftime('%A'),
                    'start_time': start_datetime.time(),
                    'end_day': end_datetime.strftime('%A'),
                    'end_time': end_datetime.time(),
                    'discount_factor': discount_factor,
                })

    # Create a DataFrame from the list of dictionaries
    time_based_rates_df = pd.DataFrame(time_based_rates)

    # Merge the time-based rates with the original DataFrame
    result_df = pd.merge(data_frame, time_based_rates_df, on=['id_start', 'id_end'], how='left')

    return result_df

# Example usage
csv_file_path = 'dataset-3.csv'  # Replace with the actual file path
result_matrix = calculate_distance_matrix(csv_file_path)
unrolled_df = unroll_distance_matrix(result_matrix)

# Assuming 'distance' is the correct column name, replace it if needed
result_df = calculate_toll_rate(unrolled_df)

# Assuming 'id_start', 'id_end' are the correct column names, replace them if needed
result_time_based_df = calculate_time_based_toll_rates(result_df)

print(result_time_based_df)